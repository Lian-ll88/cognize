# 详细项目文档

## 2.1 项目背景与价值

### 问题陈述

在当今信息爆炸的时代，知识工作者、创作者和终身学习者等“超级个体”每天都在处理海量的输入信息。然而，这种持续的信息洪流带来了“认知过载”与“知识遗忘”的双重困境。用户投入大量时间记录笔记、收藏文章，但这些信息往往是零散、被动的，难以在关键时刻被记起和调用。这导致了一个普遍的痛点：我们拥有的信息很多，但能转化为生产力的智慧却很少，最终影响了决策质量、创作深度和学习效率。

### 市场与需求分析

现有的知识管理工具，如 Notion、Obsidian 或 Evernote，在信息的**组织和存储**方面表现出色，但它们本质上是被动的数据库。用户需要手动进行分类、链接和复习。这在知识的**深度加工、智能关联和主动触发**方面留下了巨大的市场空白。用户真正需要的是一个能够模拟人类大脑进行思考的系统——它不仅能“记住”信息，更能“理解”信息，并在恰当的时机主动提供支持，将“数据”提炼为“洞察”。

### 解决方案概述

Cognize (知识蒸馏器) 正是为解决这一问题而设计的解决方案。它通过一个创新的“蒸馏-关联-触发”三步工作流，将用户的个人知识库从一个静态的存储容器，转变为一个动态的、可主动服务的智慧伙伴。Cognize 利用先进的生成式 AI 技术，将原始信息转化为结构化的认知结论，并通过向量化技术建立知识间的深层语义关联。最终，它能够在用户进行决策、内容创作或学习复习时，主动推荐最相关的历史洞察，从而赋能用户做出更明智的判断和更高质量的创造。

## 2.2 技术架构

### 技术实现

Cognize 的技术栈选择旨在实现一个轻量、高效且完全在用户端运行的纯前端应用，以最大程度地保护用户隐私并降低部署成本。

| 技术领域 | 具体技术栈 |
| --- | --- |
| **前端框架** | React 19, TypeScript, Vite |
| **UI 库** | Tailwind CSS, Lucide React |
| **AI 核心能力** | Google Gemini 1.5 Flash, Google Text Embedding 004 |
| **数据存储** | 浏览器 LocalStorage |

### 系统架构图

Cognize 的系统架构围绕着“输入-处理-存储-触发”四个核心环节构建，形成一个完整的知识内化与应用闭环。

```mmd
graph TD
    A[输入层: 文本/网页/文档] --> B{处理层};
    B --> C[1. 知识蒸馏: Gemini API];
    B --> D[2. 向量生成: Embedding API];
    C --> E[结构化洞察];
    D --> F[语义向量];
    subgraph 存储层 (LocalStorage)
        G[历史知识库: 洞察+向量];
    end
    E & F --> G;
    H[触发层: 用户查询/上下文] --> I{检索与分析};
    G --> I;
    I --> J[输出层: 相关洞察推荐];
```

*   **输入层**: 接收用户通过各种方式输入的原始信息。
*   **处理层**: 并行调用 Google AI API，一方面通过 Gemini 1.5 Flash 的 JSON Mode 进行知识蒸馏，另一方面通过 Text Embedding 模型生成语义向量。
*   **存储层**: 将蒸馏后的结构化洞察及其对应的语义向量作为一个整体（`KnowledgeRecord`）存储在浏览器的 LocalStorage 中。
*   **触发层**: 当用户进行搜索或决策查询时，系统将查询内容向量化，并在本地知识库中进行高效的向量相似度检索，找出最相关的历史记录，最终呈现给用户。

### 核心功能模块

1.  **知识蒸馏模块 (Distill)**: 此模块是信息内化的第一步。它接收非结构化的长篇文本，并强制 AI 输出一个包含“一句话结论 (Insight)”、“关键判断 (Principles)”和“可复用表述 (Reusable Phrases)”的标准化 JSON 对象，为后续的机器处理和人类理解奠定基础。

2.  **智能关联模块 (Relate)**: 在每一次新的知识被蒸馏后，此模块会立即将其向量与知识库中的现有向量进行对比。它不仅能发现语义上的相似性，还能进一步调用 AI 分析新旧知识点之间是“相似观点”、“冲突观点”还是“补充信息”，从而帮助用户构建一个动态演进的知识网络。

3.  **决策支持模块 (Decision Support)**: 这是 Cognize 将知识转化为生产力的关键出口。当用户面临一个具体问题或决策时，此模块会首先在知识库中检索出最相关的N个历史洞察作为上下文，然后将这些上下文连同用户的问题一起提交给 AI，让 AI 生成一个综合性的、有理有据的分析建议，辅助用户完成高质量决策。

## 2.3 开源相关信息

*   **开源协议**: 本项目选择 **MIT License**。我们选择此协议是因为其高度的开放性和包容性，允许任何人免费使用、修改和分发代码，这对于最大化项目的社区影响力、吸引潜在贡献者以及鼓励在本项目基础上进行二次创新至关重要。
*   **代码仓库地址**: `[待项目上传至 GitHub 后填写]`
*   **开源状态**:
    *   [x] 已开源
    *   [ ] 评审后开源
    *   [ ] 部分模块开源

## 2.4 开发进度

*   **已完成功能**: 项目的核心工作流，包括知识蒸馏、基于向量的语义搜索、本地存储以及决策支持功能均已完成并集成在基础的用户界面中。
*   **待完善功能**: 未来的开发重点将集中在扩展输入源（如语音、图片、网页链接直接解析）、优化移动端用户体验以及探索更高级的知识图谱可视化方案。
*   **遇到的挑战与解决方案**: 在开发初期，我们面临的主要挑战是如何稳定地处理 AI 返回的、有时是非结构化的文本数据。最终的解决方案是利用了 Gemini AI 先进的 **JSON Mode** 功能，通过预定义响应的 `responseSchema`，强制模型输出严格符合要求的结构化数据，极大地提升了系统的稳定性和可靠性。
*   **已知问题与局限性**: 当前版本主要依赖浏览器 LocalStorage 进行数据存储，这是一个“本地优先”的设计选择，优点是保护用户隐私且无需后端。但其局限性在于无法实现多设备间的数据同步，这是未来版本需要重点解决的问题。
